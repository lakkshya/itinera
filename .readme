Part 1 — Genetic Algorithm: deep but practical explanation

A Genetic Algorithm is a population-based metaheuristic inspired by biological evolution. It searches the space of candidate solutions by evolving a population through selection, crossover, and mutation. GAs are great for permutation problems like routing because they explore many different orders in parallel and exploit good building blocks.

Core concepts (and how each maps to optimization)

Chromosome (individual)
A representation of a candidate solution. For routing, it’s usually a permutation of place IDs (an ordered list — the visiting order).

Population
A set of chromosomes. A population explores multiple regions of the search space simultaneously.

Fitness function
A numeric score that measures how good a chromosome is. The GA tries to maximize fitness (or minimize cost — pick one convention). Fitness encodes travel time, explore times, waiting, penalties for violating constraints (open/close, daily window), and priority preferences.

Selection
Mechanism to pick parent chromosomes for reproduction. Common methods:

Tournament selection (fast and robust): pick k random individuals and choose the best.

Roulette / fitness-proportionate (less robust when fitness varies widely).

Rank selection (reduces domination by a few).

Crossover (recombination)
Combines two parents to produce children. For permutations you need operators that preserve uniqueness (no duplicate places). Popular ones:

Order Crossover (OX) — copy a slice from parent A; preserve relative order of remaining genes from parent B.

Partially Mapped Crossover (PMX) — swaps segments and repairs.

Edge Recombination — preserves adjacency information (good for TSP-like problems).

Mutation
Small random change to a chromosome to maintain diversity and escape local optima. For permutations:

Swap two indices (simple and effective).

Inversion (reverse a subsequence).

Scramble (randomize a subsequence).

Elitism
Keep top N individuals unchanged into the next generation so you never lose the best solutions found so far.

Replacement
Decide how new population is formed (replace entire pop, or generational + elitism, or steady-state).

Termination criteria
Stop after fixed generations, time budget, or when improvement stalls.

Why GAs work for routing & constraints

They combine good partial orders from different parents (crossover) while maintaining diversity (mutation).

Fitness can encode soft constraints via penalties (e.g., big penalty for arriving after closeTime) so GA balances trade-offs (priority vs travel time vs ideal windows).

Parallelizable: evaluate fitness of many chromosomes simultaneously.

Typical GA hyperparameters & practical rules

Population size: 100–400 (more for larger problems). For ≤50 places, 150–300 is reasonable.

Generations: 200–800 depending on runtime budget. More → better solution but longer time.

Crossover rate: usually 0.7–1.0 for permutation problems (you often crossover almost every pair).

Mutation rate: 0.05–0.2 (swap mutation probability per child).

Tournament size: 3–7.

Elitism: keep top 5–10%.

Tune these empirically.

Hard vs Soft constraints

Hard constraints: must be met (e.g., you must return to hotel before midnight). If violated, chromosome is infeasible — either reject it or repair it after crossover.

Soft constraints: allowed but penalized (e.g., visiting slightly outside ideal time window). Easier: make them soft using penalty terms in the fitness function. Use large penalty constants for things you really want to avoid.

Implementation notes & performance

Precompute and cache the travel-time matrix (including hotel) — fitness evaluation must be cheap.

Use a heuristic seeding of the initial population (some individuals created by nearest-neighbor or priority-based greedy) + many random permutations for diversity.

Parallelize fitness evaluation (Java ForkJoinPool or parallelStream) — evaluation is the heaviest part.

If you must run multi-day planning, either:

Cluster first into days (greedy pack) and run GA per day (faster), or

Represent days in chromosome (include day separators) — more complex but GA can optimize across days.

Part 2 — Applying GA to your itinerary (practical mapping + Java pseudocode + example)
Problem specifics you gave

Start & end each day at hotel.

Daily window: dayStart to dayEnd (e.g., 09:00–18:00).

Each place p has: openTime, closeTime, idealStart, idealEnd, exploreTime, priority.

Up to 50 places total, multi-day allowed.

I’ll assume you cluster places into days first (greedy packing), then run GA per day. This is the simplest practical approach and scales well.

Chromosome representation

For one day: represent a route as an array/list of place IDs in visiting order:

chromosome = [p3, p7, p1, p9, p4]


Implicit start and end are hotel (not included inside chromosome to keep permutation length N_day).

Fitness function (detailed)

We will compute cost (lower is better); fitness = 1 / (1 + cost) if you want higher-is-better for selection.

Cost components (all in minutes unless scaled):

travelTimeSum: sum of travel times between consecutive nodes (hotel -> first -> ... -> last -> hotel).

visitTimeSum: sum of exploreTime for each place.

waitingTime: if you arrive before openTime, you must wait — add waiting minutes.

timeWindowPenalty: large penalty if you arrive after closeTime.

idealDeviationPenalty: penalty proportional to how far your start time deviates from the ideal window midpoint (smaller weight).

priorityPenalty: encourage higher priority by subtracting (or penalizing lower priority): use a small additive penalty for lower importance.

overtimePenalty: if you return to hotel after dayEnd, add heavy penalty (or treat as infeasible).

Concrete formula:

cost = travelTimeSum + visitTimeSum + waitingTime
     + alpha * totalLateMinutes   // big alpha e.g., 100
     + beta * idealDeviationSum   // small beta e.g., 0.2
     + gamma * prioritySum        // small gamma e.g., 5
     + delta * overtimeMinutes    // big delta e.g., 50


Set constants so hard violations are strongly discouraged (alpha, delta large).

GA operators tailored to itinerary

Initial population: seed with

random permutations,

a few greedy routes (nearest neighbor starting from hotel or high-priority-first) to give good starting points.

Selection: tournament selection (k=5).

Crossover: Order Crossover (OX) — preserves subsequences and relative order. Example OX steps:

pick two cut points,

copy slice from parent A into child,

fill remaining positions from parent B in order skipping already used genes.

Mutation: swap mutation (pick two indices and swap). Also include occasional inversion.

Repair & feasibility: After crossover/mutation, the child remains a valid permutation (so no duplicate IDs). If you want to enforce hard time-window feasibility, you can:

Option A: allow infeasible children but give heavy penalty (simpler).

Option B: perform greedy local repair (shift a late place to next day or swap order to satisfy hard constraints).

Elitism: copy top 5–10% to next generation.

Java-like pseudocode (single-day GA)
List<Place> optimizeDayGA(List<Place> dayPlaces, int[][] travelTime, Place hotel, int dayStart, int dayEnd) {
    int POP = 200;
    int GEN = 400;
    double MUT_RATE = 0.12;
    int ELITES = Math.max(1, POP / 10);

    // 1. Initialize population
    List<int[]> population = new ArrayList<>();
    population.addAll(seedGreedy(dayPlaces)); // some heuristic seeds
    while (population.size() < POP) population.add(randomPermutation(dayPlaces.size()));

    for (int gen = 0; gen < GEN; gen++) {
        // 2. Evaluate fitness (cost)
        List<ScoredRoute> scored = population.stream()
            .map(route -> new ScoredRoute(route, computeCost(route, ...)))
            .sorted(Comparator.comparingDouble(ScoredRoute::getCost))
            .collect(Collectors.toList());

        List<int[]> nextPop = new ArrayList<>();
        // 3. Elitism
        for (int i = 0; i < ELITES; i++) nextPop.add(scored.get(i).route);

        // 4. Generate children
        while (nextPop.size() < POP) {
            int[] parent1 = tournamentSelect(scored);
            int[] parent2 = tournamentSelect(scored);
            int[] child = orderCrossover(parent1, parent2);
            if (Math.random() < MUT_RATE) mutateSwap(child);
            nextPop.add(child);
        }

        population = nextPop;
    }

    // return best route
    ScoredRoute best = evaluate(population).minByCost();
    return decodeRoute(best.route);
}


computeCost(route, ...) evaluates the cost using the formula above — it simulates the day starting at dayStart, iterates through route computing arrival times, waits, exploreTime, penalties, and final return to hotel.

Worked numeric example (hotel + 5 places) — full step-by-step
Setup (all times in minutes since midnight)

Hotel is at id H.

Day window: dayStart = 9:00 = 540, dayEnd = 18:00 = 1080.

Travel time matrix (minutes) including hotel (H=0) and places P1..P5 (IDs 1..5)

   H  1  2  3  4  5
H  0 10 20 15 30 25
1 10  0 12 10 20 18
2 20 12  0 14 10 22
3 15 10 14  0 16 15
4 30 20 10 16  0 12
5 25 18 22 15 12  0


Places (name, open, close, idealStart, idealEnd, exploreTime, priority):

P1: open 9:00(540), close 17:00(1020), ideal [9:30(570),11:30(690)], explore 60, priority 1
P2: open 10:00(600), close 18:00(1080), ideal [11:00(660),13:00(780)], explore 90, priority 2
P3: open 9:00(540), close 16:00(960), ideal [9:00(540),10:30(630)], explore 45, priority 1
P4: open 12:00(720), close 19:00(1140), ideal [12:30(750),14:00(840)], explore 60, priority 3
P5: open 9:00(540), close 18:00(1080), ideal [15:00(900),16:30(990)], explore 30, priority 2

Candidate chromosome (example)

[P3, P1, P2, P4, P5] — we’ll compute cost.

Simulate:

Start currentTime = 540 (9:00), current = H.

Travel H→P3 = 15 → arrival = 555.

P3 open = 540, so no wait.

idealMid = (540+630)/2 = 585. Deviation = |555 - 585| = 30 → idealPenalty = 30 * beta (take beta 0.2) = 6.

explore 45 → leave at 555+45 = 600.

priority 1 penalty = 1 * gamma (gamma=5) = 5.

Travel P3→P1 = 10 → arrival = 610.

P1 open = 570 → no wait.

idealMid = (570+690)/2 = 630. Deviation = |610 - 630| = 20 → 4 penalty.

explore 60 → leave at 670.

priority 1 → +5 penalty.

Travel P1→P2 = 12 → arrival = 682.

P2 open = 600 → ok.

idealMid = (660+780)/2 = 720. Deviation = |682 - 720| = 38 → 7.6 penalty.

explore 90 → leave at 772.

priority 2 → +10 penalty.

Travel P2→P4 = 10 → arrival = 782.

P4 open = 720 → ok.

idealMid = (750+840)/2 = 795. Deviation = |782 - 795| = 13 → 2.6 penalty.

explore 60 → leave at 842.

priority 3 → +15 penalty.

Travel P4→P5 = 12 → arrival = 854.

P5 open = 540 → ok.

idealMid = (900+990)/2 = 945. Deviation = |854 - 945| = 91 → 18.2 penalty.

explore 30 → leave at 884.

priority 2 → +10 penalty.

Travel P5→H = 25 → arrival at hotel = 909 (15:09).

This is before dayEnd 1080 → no overtime.

Now sum components:

travelTimeSum = H→P3(15) + 10 + 12 + 10 + 12 + 25 = 84

visitTimeSum = 45 + 60 + 90 + 60 + 30 = 285

waitingTime = 0

totalLateMinutes = 0 (no arrivals after close)

idealDeviationSum = 30 + 20 + 38 + 13 + 91 = 192

prioritySum = 1 + 1 + 2 + 3 + 2 = 9

Use weights: alpha=100 for late, beta=0.2, gamma=5, delta=50 for overtime.

Compute cost:

cost = travelTimeSum(84) + visitTimeSum(285) + 0
     + 100*0 + 0.2*192 + 5*9 + 50*0
     = 84 + 285 + 38.4 + 45
     = 452.4  (lower is better)


This cost is used to rank this chromosome against others.

A different permutation might reduce travel or reduce deviation penalties (e.g., placing P5 later in the day reduces ideal deviation), so GA will explore orders and favor those with lower cost.

How GA evolves this to a good route

Initial population contains many permutations (random + some greedy seeded).

Fitness evaluation computes cost for each.

Selection prefers low-cost routes.

Crossover creates children that might combine the good early visits of one parent with good late visits of another (e.g., parents that place P5 late and P4 midday can combine to reduce ideal deviations).

Mutation occasionally swaps two places to discover new orders (e.g., putting P5 at position 5 instead of 4).

After several generations, best individuals will place time-sensitive P4 around 12:30–14:00, P2 around midday, P3/P1 early morning, and P5 later — which reduces idealDeviationSum and travel deadheading — producing a low cost.

Multi-day handling (how to keep it practical)

Option A (recommended and simpler): Cluster places into days first, using a greedy packing that ensures each day's total possible time (travel + explore + return) fits inside dayEnd-dayStart. Then apply GA per day on that day's subset.

Option B (more complex): encode day separators in the chromosome (e.g., include special gene tokens to split days). GA will optimize both allocation across days and order — more powerful but more complex to design, evaluate, and repair.

Given up to 50 places, clustering then per-day GA is fast and effective.

Practical tips & improvements

Seed population with heuristics (priority-first, nearest-neighbor, and time-window-aware greedy) — speeds convergence.

Adaptive mutation: higher mutation early on, lower later.

Local search hybrid: apply a small local search (2-opt / swap improvements) to each child before inserting into population — improves final quality (memetic algorithm).

Parallel fitness evaluation: evaluate population in parallel.

Large penalties for hard constraint violations: use very high alpha, delta so GA avoids infeasible solutions.

Cache travelTime and any distance computations to keep fitness fast.

Debugging: print best route each N generations to verify it respects windows and priorities.

Summary — why GA here is a good choice

It handles complex trade-offs (travel vs priority vs time windows) naturally.

It’s flexible — you can add penalties or constraints without changing algorithm structure.

Works well with ≤50 places, especially when combined with day clustering and local search.